\section{Conclusion}\label{sec:conclusion}
In conclusion, we have implemented an optimized and parallelized implementation
of \rs{}, \block{}, and \fw{} using OpenMP, MPI, and a hybrid of the two. The
optimization of the implementations was guided by profiles generated by VTune
Amplifier and \icc{}. Ultimately, our \block{} implementations are roughly an
order of magnitude faster than the release implementation and our other
implementations for large graphs.

Perhaps the most important thing we learn from this project is that we should be aware of 
the synchronization cost when we work on a parallel problem. The Floyd-Warshall (\fw{})
which has $O(N^3)$ in computation and $O(N)$ in synchronization, is beaten by the 
repeated squares (\rs) which has $O(N^3\log N)$ in computation and $O(\log N)$ in synchronization. 
It is always a good manner to trade-off the computation and synchronization 
when we evaluate an algorithm in the parallel world. 

